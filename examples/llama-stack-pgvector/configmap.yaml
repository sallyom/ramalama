apiVersion: v1
kind: ConfigMap
metadata:
  name: llama-stack-config
data:
  ramalama-run.yaml: |
    version: '2'
    image_name: ramalama
    apis:
    - agents
    - datasetio
    - eval
    - inference
    - post_training
    - safety
    - scoring
    - telemetry
    - tool_runtime
    - vector_io
    providers:
      # all available providers can be found here: https://llama-stack.readthedocs.io/en/latest/providers/index.html
      agents:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          persistence_store:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ramalama}/agents_store.db
          responses_store:
            type: sqlite
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ramalama}/responses_store.db
      datasetio:
      - provider_id: huggingface
        provider_type: remote::huggingface
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ramalama}/huggingface_datasetio.db
      - provider_id: localfs
        provider_type: inline::localfs
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ramalama}/localfs_datasetio.db
      eval:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          kvstore:
            type: sqlite
            namespace: null
            db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ramalama}/meta_reference_eval.db
      inference:
      - provider_id: ramalama
        provider_type: remote::ramalama
        config:
          url: ${env.RAMALAMA_URL:=http://localhost:8080}
      - provider_id: sentence-transformers
        provider_type: inline::sentence-transformers
        config: {}
      post_training:
      - provider_id: huggingface
        provider_type: inline::huggingface
        config:
          checkpoint_format: huggingface
          distributed_backend: null
          device: cpu
      safety:
      - provider_id: llama-guard
        provider_type: inline::llama-guard
        config:
          excluded_categories: []
      scoring:
      - provider_id: basic
        provider_type: inline::basic
        config: {}
      - provider_id: llm-as-judge
        provider_type: inline::llm-as-judge
        config: {}
      - provider_id: braintrust
        provider_type: inline::braintrust
        config:
          openai_api_key: ${env.OPENAI_API_KEY:+}
      telemetry:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          service_name: ${env.OTEL_SERVICE_NAME:=llamastack}
          sinks: ${env.TELEMETRY_SINKS:=console,sqlite}
          sqlite_db_path: ${env.SQLITE_DB_PATH:=~/.llama/distributions/ramalama}/trace_store.db
      tool_runtime:
      - provider_id: brave-search
        provider_type: remote::brave-search
        config:
          api_key: ${env.BRAVE_SEARCH_API_KEY:+}
          max_results: 3
      - provider_id: tavily-search
        provider_type: remote::tavily-search
        config:
          api_key: ${env.TAVILY_SEARCH_API_KEY:+}
          max_results: 3
      - provider_id: rag-runtime
        provider_type: inline::rag-runtime
        config: {}
      - provider_id: model-context-protocol
        provider_type: remote::model-context-protocol
        config: {}
      - provider_id: wolfram-alpha
        provider_type: remote::wolfram-alpha
        config:
          api_key: ${env.WOLFRAM_ALPHA_API_KEY:+}
      vector_io:
      - provider_id: pgvector
        provider_type: remote::pgvector
        config:
          host: ${env.POSTGRES_HOST:=127.0.0.1}
          port: ${env.POSTGRES_PORT:=5432}
          db: ${env.PGVECTOR_DBNAME:=rag_blueprint}
          user: ${env.POSTGRES_USER:=postgres}
          password: ${env.POSTGRES_PASSWORD:=rag_password}
    metadata_store:
      type: sqlite
      db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ramalama}/registry.db
    inference_store:
      type: sqlite
      db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/ramalama}/inference_store.db
    models:
    - metadata: {}
      model_id: ${env.INFERENCE_MODEL}
      provider_id: ramalama
      model_type: llm
    - metadata:
        embedding_dimension: 384
      model_id: all-MiniLM-L6-v2
      provider_id: sentence-transformers
      model_type: embedding
    shields: []
    vector_dbs: []
    datasets: []
    scoring_fns: []
    benchmarks: []
    tool_groups:
    - toolgroup_id: builtin::websearch
      provider_id: tavily-search
    - toolgroup_id: builtin::rag
      provider_id: rag-runtime
    - toolgroup_id: builtin::wolfram_alpha
      provider_id: wolfram-alpha
    server:
      port: 8321
    external_providers_dir: ${env.EXTERNAL_PROVIDERS_DIR:=~/.llama/providers.d}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: pgvector-init
data:
  init-db.sh: |
    #!/bin/bash
    set -e

    # Create the database and enable vector extension
    psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname "$POSTGRES_DB" <<-EOSQL
        CREATE EXTENSION IF NOT EXISTS vector;
        
        -- Grant necessary permissions
        GRANT ALL PRIVILEGES ON DATABASE $POSTGRES_DB TO $POSTGRES_USER;
        
        -- Create a table for testing vector operations (optional)
        CREATE TABLE IF NOT EXISTS embeddings (
            id SERIAL PRIMARY KEY,
            content TEXT,
            embedding VECTOR(384)
        );
    EOSQL

    echo "PGVector database initialized successfully"
